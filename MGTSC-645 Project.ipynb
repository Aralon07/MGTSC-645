{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a0b09f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   row_id        order_id  order_date   ship_date       ship_mode customer_id  \\\n",
      "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
      "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "\n",
      "     customer_name    segment        country             city  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  postal_code  region       product_id         category sub_category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        product_name     sales  quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   discount    profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Dataset Info (Before Cleaning):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   row_id         9994 non-null   int64  \n",
      " 1   order_id       9994 non-null   object \n",
      " 2   order_date     9994 non-null   object \n",
      " 3   ship_date      9994 non-null   object \n",
      " 4   ship_mode      9994 non-null   object \n",
      " 5   customer_id    9994 non-null   object \n",
      " 6   customer_name  9994 non-null   object \n",
      " 7   segment        9994 non-null   object \n",
      " 8   country        9994 non-null   object \n",
      " 9   city           9994 non-null   object \n",
      " 10  state          9994 non-null   object \n",
      " 11  postal_code    9994 non-null   int64  \n",
      " 12  region         9994 non-null   object \n",
      " 13  product_id     9994 non-null   object \n",
      " 14  category       9994 non-null   object \n",
      " 15  sub_category   9994 non-null   object \n",
      " 16  product_name   9994 non-null   object \n",
      " 17  sales          9994 non-null   float64\n",
      " 18  quantity       9994 non-null   int64  \n",
      " 19  discount       9994 non-null   float64\n",
      " 20  profit         9994 non-null   float64\n",
      "dtypes: float64(3), int64(3), object(15)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "Missing Values per Column:\n",
      "row_id           0\n",
      "order_id         0\n",
      "order_date       0\n",
      "ship_date        0\n",
      "ship_mode        0\n",
      "customer_id      0\n",
      "customer_name    0\n",
      "segment          0\n",
      "country          0\n",
      "city             0\n",
      "state            0\n",
      "postal_code      0\n",
      "region           0\n",
      "product_id       0\n",
      "category         0\n",
      "sub_category     0\n",
      "product_name     0\n",
      "sales            0\n",
      "quantity         0\n",
      "discount         0\n",
      "profit           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Order Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Order Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m date_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShip Date\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Modify if needed\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m date_columns:\n\u001b[0;32m---> 41\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Drop columns that are useless for analysis (modify this list as needed)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRow ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostal Code\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Example: Remove identifiers that are not useful\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Order Date'"
     ]
    }
   ],
   "source": [
    "\n",
    "#This comment is to add the code to my branch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os  # Import os to work with environment variables\n",
    "\n",
    "# Get the file path from the DATA_PATH environment variable\n",
    "data_path = os.getenv(\"DATA_PATH\", \"/Users/raylu/Desktop/Courses/MGTSC 645/FInal Project\")  # Adjust default path if needed\n",
    "\n",
    "# Combine the directory with the filename\n",
    "file_path = os.path.join(data_path, \"superstore.csv\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Replace spaces with underscores, convert to lowercase, remove hyphens and strip extra whitespaces\n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace('-', '_').str.lower().str.strip()\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display dataset info\n",
    "print(\"\\nDataset Info (Before Cleaning):\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Check for missing values **(but do not fill them)**\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Convert columns to correct data types\n",
    "date_columns = ['Order Date', 'Ship Date']  # Modify if needed\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Drop columns that are useless for analysis (modify this list as needed)\n",
    "columns_to_drop = ['Row ID', 'Postal Code']  # Example: Remove identifiers that are not useful\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Ensure correct data types\n",
    "print(\"\\nUpdated Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65651be6-0b61-42f0-a1a9-c8c1b71501a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
